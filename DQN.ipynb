{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e50b732",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dq/qs6r2tv50msd_4519dqqkfxw0000gq/T/ipykernel_57197/1655069499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import rl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8bb5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /Users/jezeehu/opt/anaconda3/lib/python3.9/site-packages (from gym) (1.21.5)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/jezeehu/opt/anaconda3/lib/python3.9/site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/jezeehu/opt/anaconda3/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jezeehu/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym) (3.8.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827632 sha256=c4af52fc60531303037bcc00c0732e51be432efd987623878c74e82ced9d2c35\n",
      "  Stored in directory: /Users/jezeehu/Library/Caches/pip/wheels/af/2b/30/5e78b8b9599f2a2286a582b8da80594f654bf0e18d825a4405\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, gym\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2538928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import rl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d58810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    '''经验回放池'''\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity) #队列，先进先出\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done): #将数据加入buffer\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def sample(self, batch_size): #从buffer中采样数据，数量大小未batch_size\n",
    "        transitions = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = zip(transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bc1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(torch.nn.Module):\n",
    "    '''只有一层隐藏层的Q网络'''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) #隐层使用ReLU激活函数\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e163b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, learning_rate, gamma,\n",
    "                epsilon, target_update, device):\n",
    "        self.action_dim = action_dim\n",
    "        self.q_net = Qnet(state_dim, hidden_dim, self.action_dim).to(device) #Q网络\n",
    "        self.target_q_net = Qnet(state_dim, hidden_dim, self.action_dim).to(device) #目标网络\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr = learning_rate)\n",
    "        \n",
    "        self.gamma = gamma #折扣因子\n",
    "        self.epsilon = epsilon #epsilon-贪婪策略\n",
    "        self.target_update = target_update  #目标网络更新频率\n",
    "        self.count = 0 #计数器，记录更新次数\n",
    "        self.device = device\n",
    "    \n",
    "    def take_action(self, state): #epsilon-贪婪策略采取动作\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(self.action_dim)\n",
    "        else:\n",
    "            state = torch.tensor([state], dtype=torch.float).to(self.device)\n",
    "            action = self.q_net(state).argmax().item()\n",
    "        return action\n",
    "    \n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        \n",
    "        q_values = self.q_net(states).gather(1, actions) #Q值\n",
    "        #下个状态的最大Q值\n",
    "        max_next_q_values = self.target_q_net(next_states).max(1)[0].view(-1, 1)\n",
    "        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones) #TD误差目标\n",
    "        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets)) #均方误差损失函数\n",
    "        self.optimizer.zero_grad() #pytorch中默认梯度会累计，需要显式将梯度置为0\n",
    "        dqn_loss.backward() #反向传播更新参数\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if self.count % self.target_update == 0:\n",
    "            self.target_q_net.load_stete_dict(self.q_net.state_dict()) #更新目标网络\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40868c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
